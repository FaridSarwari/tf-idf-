{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.  Tokenization<h3>\n",
    "\n",
    "#### The process of splitting text into its most simple form - that is from a sentence into individual keywords. In order to preprocess this for most of our models, we typically lowercase the sentence and remove any punctuation.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case our list of words from a document df\n",
    "df = df.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation from list of words\n",
    "for p in string.punctation:\n",
    "    t = t.replace(p, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a list of tokens \n",
    "tokens = t.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Stemming/Lemmatization<h3>\n",
    "    \n",
    "#### The process of obtaining the root of keywords as certain words have conjugations. For instace, in the sentences \"I love running\" and \"I went for a run\", the word \"running/run\" mean the same the thing however, are taken as two separate tokens.\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>3. TF-IDF: News Article Title <h3>\n",
    "    \n",
    "#### Bag-of-Words Model\n",
    "##### Takes into consideration the number of times a word appears in a document, divided by the total number of words in the document. Every document has its own term frequency.\n",
    "##### It tells us how important a word, or keyword is in a document, in terms of how much overall information it contributes to in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import advertools as adv\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 13:36:24,547 | INFO | sitemaps.py:536 | sitemap_to_df | Getting https://www.dailymail.co.uk/google-news-sitemap2.xml\n",
      "2022-07-12 13:36:24,671 | INFO | sitemaps.py:536 | sitemap_to_df | Getting https://www.dailymail.co.uk/google-news-sitemap1.xml\n",
      "2022-07-12 13:36:24,932 | INFO | sitemaps.py:536 | sitemap_to_df | Getting http://www.theguardian.com/sitemaps/news.xml\n"
     ]
    }
   ],
   "source": [
    "df_dailymail = adv.sitemap_to_df(\"https://www.dailymail.co.uk/google-news-sitemap.xml\")\n",
    "df_guardian = adv.sitemap_to_df(\"http://www.theguardian.com/sitemaps/news.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Boy, 16, dies after getting into difficulty wh...\n",
       "1       A whole different ball game! Joe Cole visits D...\n",
       "2       Terry admits to 'turning down three managerial...\n",
       "3       Channel 10's struggling breakfast show has jus...\n",
       "4       Love Island: Fans are left reeling as Adam Col...\n",
       "                              ...                        \n",
       "1189    Special needs girl, 16, and her mother, 51, ar...\n",
       "1190    Steven Tyler's daughter Mia puts her Hollywood...\n",
       "1191    Noble Park shooting kills one person as gunman...\n",
       "1192    Sofia Vergara is stunning as she celebrates he...\n",
       "1193    Boy, 16, dies after getting into difficulty wh...\n",
       "Name: news_title, Length: 1194, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dailymail['news_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Tell us: have you contacted or been contacted ...\n",
       "1      Tour de France 2022: stage 10 from Morzine to ...\n",
       "2      England v India: first one-day international –...\n",
       "3      Tiger Woods blasts LIV rebels for turning thei...\n",
       "4                Boots to stop making lower-SPF suncream\n",
       "                             ...                        \n",
       "543                  Why is listening to music pleasant?\n",
       "544    The lesson from Johnson’s tenure – British pol...\n",
       "545    Readers reply: which sport is the most difficu...\n",
       "546    The cult of confidence: could positive thinkin...\n",
       "547    Our sweet little dog needed a friend. No one w...\n",
       "Name: news_title, Length: 548, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guardian['news_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boy, 16, dies after getting into difficulty while swimming in abandoned Wigan quarry  \n"
     ]
    }
   ],
   "source": [
    "documentA = df_dailymail['news_title'][0]\n",
    "print(documentA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell us: have you contacted or been contacted by an old friend? \n"
     ]
    }
   ],
   "source": [
    "documentB = df_guardian['news_title'][0]\n",
    "print(documentB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting our list on empty space to obtain a list of all words\n",
    "bagOfWordsA = documentA.split(' ')\n",
    "bagOfWordsB = documentB.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting all the unique words in both documents\n",
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'old', 'Wigan', '', 'an', 'by', 'in', 'quarry\\xa0\\xa0', 'swimming', 'difficulty', 'or', 'Tell', 'getting', 'friend?', '16,', 'into', 'us:', 'have', 'you', 'dies', 'abandoned', 'contacted', 'Boy,', 'while', 'been', 'after'}\n"
     ]
    }
   ],
   "source": [
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary for both our documents, showing the count of each uniqe word in each document\n",
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'old': 0, 'Wigan': 1, '': 0, 'an': 0, 'by': 0, 'in': 1, 'quarry\\xa0\\xa0': 1, 'swimming': 1, 'difficulty': 1, 'or': 0, 'Tell': 0, 'getting': 1, 'friend?': 0, '16,': 1, 'into': 1, 'us:': 0, 'have': 0, 'you': 0, 'dies': 1, 'abandoned': 1, 'contacted': 0, 'Boy,': 1, 'while': 1, 'been': 0, 'after': 1}\n",
      "{'old': 1, 'Wigan': 0, '': 1, 'an': 1, 'by': 1, 'in': 0, 'quarry\\xa0\\xa0': 0, 'swimming': 0, 'difficulty': 0, 'or': 1, 'Tell': 1, 'getting': 0, 'friend?': 1, '16,': 0, 'into': 0, 'us:': 1, 'have': 1, 'you': 1, 'dies': 0, 'abandoned': 0, 'contacted': 2, 'Boy,': 0, 'while': 0, 'been': 1, 'after': 0}\n"
     ]
    }
   ],
   "source": [
    "print(numOfWordsA)\n",
    "print(numOfWordsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'old': 0.0, 'Wigan': 0.07692307692307693, '': 0.0, 'an': 0.0, 'by': 0.0, 'in': 0.07692307692307693, 'quarry\\xa0\\xa0': 0.07692307692307693, 'swimming': 0.07692307692307693, 'difficulty': 0.07692307692307693, 'or': 0.0, 'Tell': 0.0, 'getting': 0.07692307692307693, 'friend?': 0.0, '16,': 0.07692307692307693, 'into': 0.07692307692307693, 'us:': 0.0, 'have': 0.0, 'you': 0.0, 'dies': 0.07692307692307693, 'abandoned': 0.07692307692307693, 'contacted': 0.0, 'Boy,': 0.07692307692307693, 'while': 0.07692307692307693, 'been': 0.0, 'after': 0.07692307692307693}\n",
      "{'old': 0.07692307692307693, 'Wigan': 0.0, '': 0.07692307692307693, 'an': 0.07692307692307693, 'by': 0.07692307692307693, 'in': 0.0, 'quarry\\xa0\\xa0': 0.0, 'swimming': 0.0, 'difficulty': 0.0, 'or': 0.07692307692307693, 'Tell': 0.07692307692307693, 'getting': 0.0, 'friend?': 0.07692307692307693, '16,': 0.0, 'into': 0.0, 'us:': 0.07692307692307693, 'have': 0.07692307692307693, 'you': 0.07692307692307693, 'dies': 0.0, 'abandoned': 0.0, 'contacted': 0.15384615384615385, 'Boy,': 0.0, 'while': 0.0, 'been': 0.07692307692307693, 'after': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(tfA)\n",
    "print(tfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>Wigan</th>\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>by</th>\n",
       "      <th>in</th>\n",
       "      <th>quarry</th>\n",
       "      <th>swimming</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>or</th>\n",
       "      <th>...</th>\n",
       "      <th>us:</th>\n",
       "      <th>have</th>\n",
       "      <th>you</th>\n",
       "      <th>dies</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>contacted</th>\n",
       "      <th>Boy,</th>\n",
       "      <th>while</th>\n",
       "      <th>been</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        old     Wigan                  an        by        in  quarry    \\\n",
       "0  0.000000  0.053319  0.000000  0.000000  0.000000  0.053319  0.053319   \n",
       "1  0.053319  0.000000  0.053319  0.053319  0.053319  0.000000  0.000000   \n",
       "\n",
       "   swimming  difficulty        or  ...       us:      have       you  \\\n",
       "0  0.053319    0.053319  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1  0.000000    0.000000  0.053319  ...  0.053319  0.053319  0.053319   \n",
       "\n",
       "       dies  abandoned  contacted      Boy,     while      been     after  \n",
       "0  0.053319   0.053319   0.000000  0.053319  0.053319  0.000000  0.053319  \n",
       "1  0.000000   0.000000   0.106638  0.000000  0.000000  0.053319  0.000000  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF using sklearn's vectorizer library\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>after</th>\n",
       "      <th>an</th>\n",
       "      <th>been</th>\n",
       "      <th>boy</th>\n",
       "      <th>by</th>\n",
       "      <th>contacted</th>\n",
       "      <th>dies</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>...</th>\n",
       "      <th>into</th>\n",
       "      <th>old</th>\n",
       "      <th>or</th>\n",
       "      <th>quarry</th>\n",
       "      <th>swimming</th>\n",
       "      <th>tell</th>\n",
       "      <th>us</th>\n",
       "      <th>while</th>\n",
       "      <th>wigan</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.267261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        16  abandoned    after        an      been      boy        by  \\\n",
       "0  0.27735    0.27735  0.27735  0.000000  0.000000  0.27735  0.000000   \n",
       "1  0.00000    0.00000  0.00000  0.267261  0.267261  0.00000  0.267261   \n",
       "\n",
       "   contacted     dies  difficulty  ...     into       old        or   quarry  \\\n",
       "0   0.000000  0.27735     0.27735  ...  0.27735  0.000000  0.000000  0.27735   \n",
       "1   0.534522  0.00000     0.00000  ...  0.00000  0.267261  0.267261  0.00000   \n",
       "\n",
       "   swimming      tell        us    while    wigan       you  \n",
       "0   0.27735  0.000000  0.000000  0.27735  0.27735  0.000000  \n",
       "1   0.00000  0.267261  0.267261  0.00000  0.00000  0.267261  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the TFIDF vectorizer from sklearn library does smoothing, meaning our values are close or similar to the above computed values\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
